
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "spark-history-server.name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "spark-history-server.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "spark-history-server.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "spark-history-server.labels" . | nindent 8 }}
    spec:
    {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
    {{- end }}
      serviceAccountName: {{ include "spark-history-server.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          args: [
              "/bin/sh",
              "-c",
              "/opt/spark/sbin/start-history-server.sh"
          ]
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.s3.existingSecret }}
                  key: {{ .Values.s3.accessKeyKey }}
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.s3.existingSecret }} 
                  key: {{ .Values.s3.secretKeyKey }}
            - name: SPARK_NO_DAEMONIZE
              value: "false"
            - name: SPARK_HISTORY_OPTS
              value: "-Dspark.history.fs.logDirectory={{ .Values.s3.logDirectory }} \
                      -Dspark.hadoop.fs.s3a.endpoint={{ .Values.s3.endpoint }} \
                      -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
                      -Dspark.hadoop.fs.s3a.committer.magic.enabled=true \
                      -Dspark.hadoop.fs.s3a.path.style.access=true \
                      -Dspark.hadoop.fs.s3a.committer.staging.abort.pending.uploads=true \
                      -Dspark.hadoop.fs.s3a.block.size=512M \
                      -Dspark.hadoop.fs.s3a.committer.staging.conflict-mode=append \
                      -Dcom.amazonaws.sdk.disableCertChecking={{ .Values.s3.disableCertChecking }}"
            - name: SPARK_CONF_DIR
              value: /opt/spark/conf
          volumeMounts:
            - name: config-volume
              mountPath: /opt/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            {{- if .Values.ssl.enabled }}
            - name: keystore-volume
              mountPath: /mnt/secrets/keystore.jks
              subPath: keystore.jks
              readOnly: true
            {{- end }}
            {{- if .Values.ssl.enabled }}
            - name: truststore-volume
              mountPath: /mnt/secrets/truststore.jks
              subPath: truststore.jks
              readOnly: true
            {{- end }}
          ports:
            - name: http
              containerPort: {{ .Values.service.internalPort }}
              protocol: TCP
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      volumes:
        - name: config-volume
          configMap:
            name: {{ template "spark-history-server.name" . }}-config
        {{- if .Values.ssl.enabled }}
        - name: keystore-volume
          secret:
            secretName: {{ .Values.ssl.keystoreSecretName }}
        {{- end }}
        {{- if .Values.ssl.enabled }}
        - name: truststore-volume
          secret:
            secretName: {{ .Values.ssl.truststoreSecretName }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
    {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
    {{- end }}
    {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
    {{- end }}

